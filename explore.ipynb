{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8a4c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bk/zhdff0zs3yz8v31x8wdnftxm0000gn/T/ipykernel_61940/2223559305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLassoLars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTweedieRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_db_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'env'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from env import get_db_url\n",
    "import acquire\n",
    "import prepare\n",
    "from prepare import percentage_stacked_plot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fcd1f4",
   "metadata": {},
   "source": [
    "# Explore data (on train only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brings in acquire.py\n",
    "df = acquire.get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78db8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# runs prepare functions\n",
    "df = prepare.prep_zillow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4e799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5eadc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits my data\n",
    "train_validate, test = train_test_split(df, test_size = 0.10, random_state = 123)\n",
    "train, validate = train_test_split(train_validate, test_size = 0.20, random_state = 123)\n",
    "print(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list discrete columns\n",
    "discrete = [col for col in [col for col in train.columns if train[col].dtypes in ['int64','float64']] if 'sqft' not in col and  'cnt' not in col and  'nbr' not in col and 'number' not in col and len(train[col].unique())< 50  ]\n",
    "# print('we have {} columns of discrete variables which are columns with unique values less than 50'.format(len(discrete)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list continuous columns\n",
    "continuous = [col for col in [col for col in train.columns if train[col].dtypes in ['int64','float64']] if col not in discrete]\n",
    "# print('we have {} columns of continuous variable which are columns with unique values more than 50'.format(len(continuous)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2957902",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot parameter values in graph\n",
    "def univariate(data,col,vartype=[0,1],hue =None):    \n",
    "    '''\n",
    "    Univariate function will plot parameter values in graphs.\n",
    "    df      : dataframe name\n",
    "    col     : Column name\n",
    "    vartype : variable type : continuous or categorical\n",
    "                Continuous(0)   : Distribution, Violin & Boxplot will be plotted.\n",
    "                Categorical(1) : Countplot will be plotted.\n",
    "    hue     : Only applicable in categorical analysis.\n",
    "    '''\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    df = data.copy()\n",
    "    if vartype == 0:\n",
    "        fig, ax=plt.subplots(nrows =1,ncols=5,figsize=(20,6))\n",
    "        #\n",
    "        ax[0].set_title(col+\" Distribution Plot\")\n",
    "        sns.distplot(df[col],ax=ax[0])\n",
    "\n",
    "        ax[1].set_title(col+\" Violin Plot\")\n",
    "        sns.violinplot(data =df, x=col,ax=ax[1], inner=\"quartile\")#.set(ylabel='')\n",
    "        #\n",
    "        ax[2].set_title(col+\" Box Plot\")\n",
    "        sns.boxplot(data =df, x=col,ax=ax[2],orient='v')\n",
    "        #\n",
    "        ax[3].set_title(col+\" strip Plot\")\n",
    "        sns.stripplot(data =df, x=col,ax=ax[3])\n",
    "        df[col]=np.log(df[col])\n",
    "        ax[4].set_title(col+\" scatter Plot\")\n",
    "        sns.scatterplot(x =df[col], y=df['logerror'],ax=ax[4])\n",
    "\n",
    "        \n",
    "\n",
    "    if vartype == 1:\n",
    "        temp = pd.Series(data = hue)\n",
    "        fig, ax = plt.subplots()\n",
    "      \n",
    "        width = len(df[col].unique()) + 3 + 2*len(temp.unique())\n",
    "        fig.set_size_inches(width , 4)\n",
    "        ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue) \n",
    "        if len(temp.unique()) > 0:\n",
    "            for p in ax.patches:\n",
    "                ax.annotate('{:1.1f}%'.format((p.get_height()*100)/float(len(df))), (p.get_x()+0.05, p.get_height()+10))  \n",
    "        else:\n",
    "            for p in ax.patches:\n",
    "                ax.annotate(p.get_height(), (p.get_x()+0.16, p.get_height()+10)) \n",
    "        del temp\n",
    "    else:\n",
    "        exit\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in train[continuous].columns:\n",
    "#univariate(train,col,0,hue =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d039e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete = [ col for col in discrete if train[col].nunique()>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train[discrete].columns:\n",
    "  univariate(train,col,1,hue =train.transaction_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporal data distribution\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.countplot(x=train.transaction_month).set_title(\"Transaction distribution based on month\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d010010",
   "metadata": {},
   "source": [
    "## May has the highest amount of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=train.index,y=train.log_error,hue=train.transaction_month).set_title(\"Logerror based on transaction month\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list my categorical columns\n",
    "categorical = [col for col in train.columns if train[col].dtypes  in ['object'] ]\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists the columns I am using\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60393877",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [col for col in train.columns if train[col].dtypes  in ['object'] ]\n",
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a43903",
   "metadata": {},
   "source": [
    "### Identifying relationships between tax_amount and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.transaction_month, y=train.tax_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts the number of transactions in each month\n",
    "train.transaction_month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a7564",
   "metadata": {},
   "source": [
    "### May is the highest month for transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots lats/longs by tax amount\n",
    "sns.scatterplot(x=train.latitude , y=train.longitude, hue=train.tax_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.tax_rate , y=train.square_feet, hue=train.tax_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa8ac4",
   "metadata": {},
   "source": [
    "### the higher the square_feet, the higher the tax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.tax_amount , y=train.bedrooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011e86a",
   "metadata": {},
   "source": [
    "### 3 and 4 bedrooms have the highest tax_amount as represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ac9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.bedrooms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=train.tax_value, y=train.tax_amount, hue=train.square_feet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bbef6",
   "metadata": {},
   "source": [
    "### the higher the square_feet the higher the tax_amount and tax value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ed9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x= train[train.tax_value<1000000].county, y= train[train.tax_value<100000].tax_value, data=train[train.tax_value<100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf394777",
   "metadata": {},
   "source": [
    "### Highest tax values are in Orange county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing distribution of tax_values\n",
    "sns.distplot(train.tax_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a subset of df with continuous variables to create pairplot\n",
    "train_corr = train[['bathrooms', 'bedrooms', 'square_feet', 'lot_size', 'tax_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014675f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using corr() function to find correlation between columns\n",
    "train_corr = train_corr.corr()\n",
    "train_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a80b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots heatmap and correlation values \n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(train_corr, annot=True, cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653a15d",
   "metadata": {},
   "source": [
    "### $H_0$: there is no relationship between tax values and number of bedrooms, bathrooms and square_feet\n",
    "### $H_a$: There is a relationship between tax values and number of bedrooms, bathrooms and square_feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d216d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets take a look at simple model based on bathoom, bedroom and squarefeet and compare if against the baseline(median home value)\n",
    "X_train = train[['bedrooms', 'bathrooms', 'square_feet']]\n",
    "y_train = train[['tax_value']]\n",
    "y_train['y_baseline'] = train['tax_value'].median()\n",
    "# predictor/independent features split into train, test, validate\n",
    "X_train = train.drop(columns = ['tax_value'],axis=1)\n",
    "X_validate = validate.drop(columns = ['tax_value'],axis=1)\n",
    "X_test = test.drop(columns = ['tax_value'],axis=1)\n",
    "\n",
    "# target variables split into train, test, validate\n",
    "#y_train = train.tax_value\n",
    "y_validate = validate.tax_value\n",
    "y_test = test.tax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e73464",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a82495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the baseline (based on median) RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_baseline = sqrt(mean_squared_error(y_train.tax_value, y_train.y_baseline))\n",
    "\n",
    "rmse_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now create a OLS model based on bedrooms, bathrooms and square_feet\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# generate parameters, i.e. create model\n",
    "ols_model = ols('tax_value ~ bedrooms + bathrooms + square_feet', data = train).fit()\n",
    "\n",
    "# compute predictions and add to original dataframe\n",
    "y_train['yhat'] = ols_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac52fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    " y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3448d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030540ba",
   "metadata": {},
   "source": [
    "### My p-values are <0.05, I can reject my null hypothesis.\n",
    "### This means that there is statistically significant relationship between tax_values and the independent variables I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d48125",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(y_train.tax_value, y_train.yhat))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c6a73d",
   "metadata": {},
   "source": [
    "###  RMSE for OLS model with bedrooom, bathroom and square feet 201147 < the baseline 219730.  R2 is 0.15 and p-value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22771bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe 'predictions' with actual tax_values\n",
    "predictions = pd.DataFrame({\n",
    "    'actual': y_train.tax_value\n",
    "})\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train[['bedrooms', 'bathrooms', 'square_feet']]\n",
    "y_train1 = y_train[['tax_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7137c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression model\n",
    "lm = LinearRegression()\n",
    "# fit our train data on the model\n",
    "lm.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a634c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Model:\", lm)\n",
    "\n",
    "print(\"intercept: \", lm.intercept_)\n",
    "\n",
    "print(\"coefficients: \", lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions from linear regresssion model based on X_train independent variable values\n",
    "predictions['yhat_lm'] = lm.predict(X_train1)\n",
    "#Baseline predicted home value (median home price)\n",
    "predictions['baseline'] = y_train.tax_value.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lamda and calculate RMSE for each columns in prediction dataframe\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "predictions.apply(lambda col: sqrt(mean_squared_error(predictions.actual, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177264a1",
   "metadata": {},
   "source": [
    "### RMSE performs better than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc00dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using test data and predicting tax values based on linear model above\n",
    "X_test = test[['bedrooms', 'bathrooms', 'square_feet']]\n",
    "y_test = test[['tax_value']]\n",
    "y_test['test_prediction'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55519617",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.rename(columns = {'tax_value': 'actual'}, inplace = True)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating RMSE for test predictions\n",
    "y_test.apply(lambda col: sqrt(mean_squared_error(y_test.actual, col)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare baseline\n",
    "rmse_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ca475",
   "metadata": {},
   "source": [
    "### RMSE for test data is lower than train data and shows LM is better than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mth = sns.kdeplot(train.bedrooms[(train[\"tax_value\"] == 0) ],\n",
    "                color=\"#0072BD\", shade = True)\n",
    "Mth = sns.kdeplot(train.bedrooms[(train[\"tax_value\"] == 1) ],\n",
    "                ax =Mth, color=\"#ebb086\", shade= True)\n",
    "Mth.legend([\"No Churn\",\"Churn\"])\n",
    "Mth.set_ylabel('Density')\n",
    "Mth.set_xlabel('Monthly Charges')\n",
    "Mth.set_title('Monthly charges by churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d552b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
